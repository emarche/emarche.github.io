<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p><img title="VFS" alt="General architecture of Value Function Search" src="/assets/img/publication_preview/ICLR2023_vfs.png" class="post-image"></p> <p class="post-abstract">Deep Policy Gradient (PG) algorithms employ value networks to drive the learning of parameterized policies and reduce the variance of the gradient estimates. However, value function approximation gets stuck in local optima and struggles to fit the actual return, limiting the variance reduction efficacy and leading policies to sub-optimal performance. In this paper, we focus on improving value approximation and analyzing the effects on Deep PG primitives such as value prediction, variance reduction, and correlation of gradient estimates with the true gradient. To this end, we introduce a Value Function Search that employs a population of perturbed value networks to search for a better approximation. Our framework does not require additional environment interactions, gradient computations, or ensembles, providing a computationally inexpensive approach to enhance the supervised learning task on which value networks train. Crucially, we show that improving Deep PG primitives results in improved sample efficiency and policies with higher returns using common continuous control benchmark domains.</p> <h3>Citation</h3> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ICLR2023_vfs</span><span class="p">,</span>
    <span class="na">title</span><span class="p">=</span><span class="s">{Improving Deep Policy Gradients via Value Function Search}</span><span class="p">,</span>
    <span class="na">author</span><span class="p">=</span><span class="s">{Marchesini, Enrico and Amato, Christopher}</span><span class="p">,</span>
    <span class="na">booktitle</span><span class="p">=</span><span class="s">{International Conference on Learning Representations (ICLR)}</span><span class="p">,</span>
    <span class="na">year</span><span class="p">=</span><span class="s">{2023}</span><span class="p">,</span>
    <span class="na">url</span><span class="p">=</span><span class="s">{https://openreview.net/forum?id=6qZC7pfenQm}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div> </body></html>